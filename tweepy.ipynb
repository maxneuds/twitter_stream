{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import configparser\n",
    "import time\n",
    "import tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_conf = 'conf/settings.ini'\n",
    "config = configparser.ConfigParser()\n",
    "config.read(path_conf)\n",
    "keys = config['KEYS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TWITTER_APP_KEY = keys['TWITTER_APP_KEY']\n",
    "TWITTER_APP_SECRET = keys['TWITTER_APP_SECRET']\n",
    "TWITTER_KEY = keys['TWITTER_KEY']\n",
    "TWITTER_SECRET = keys['TWITTER_SECRET']\n",
    "\n",
    "auth = tweepy.OAuthHandler(TWITTER_APP_KEY, TWITTER_APP_SECRET)\n",
    "auth.set_access_token(TWITTER_KEY, TWITTER_SECRET)\n",
    "\n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "from streamz import Stream\n",
    "from streamz.dataframe import DataFrame\n",
    "from datetime import datetime as dt\n",
    "import pandas as pd\n",
    "import json\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# build listener for new tweets\n",
    "\n",
    "# create a listener that prints the text of any tweet that comes from the Twitter API.\n",
    "class StreamListener(tweepy.StreamListener):\n",
    "  def __init__(self, time_limit=60):\n",
    "    # set time limit and counter\n",
    "    self.start_time = time.time()\n",
    "    self.limit = time_limit\n",
    "    self.counter = 0\n",
    "    # define source and sink\n",
    "    self.source = Stream()\n",
    "    self.sink = {}\n",
    "    # count hashtags\n",
    "    clear_output()\n",
    "    self.source\\\n",
    "      .map(self.hashtags)\\\n",
    "      .accumulate(self.sum_hashtags)\\\n",
    "      .sink(self.sink.update)\n",
    "    super(StreamListener, self).__init__()\n",
    "  \n",
    "  def on_status(self, status):\n",
    "    # skip retweets\n",
    "    if hasattr(status, \"retweeted_status\"):\n",
    "      return\n",
    "    # process tweets\n",
    "    if hasattr(status, \"extended_tweet\"):\n",
    "      text = status.extended_tweet[\"full_text\"]\n",
    "    else:\n",
    "      text = status.text\n",
    "    id_str = status.id_str\n",
    "    name = status.user.screen_name\n",
    "    ts = dt.now().timestamp()\n",
    "    # create data dict\n",
    "    data = {'id': id_str, 'name': name, 'text': text, 'ts': ts}\n",
    "    # emit data to source\n",
    "    self.source.emit(data)\n",
    "    self.counter += 1\n",
    "    # check for sink cleanup\n",
    "    if self.counter % 1000 == 0:\n",
    "      self.clean_sink()\n",
    "    # check for end\n",
    "    if (time.time() - self.start_time) < self.limit:\n",
    "      return True\n",
    "    else:\n",
    "      return False\n",
    "\n",
    "  def on_error(self, status_code):\n",
    "    print(f'Error: {status_code}')\n",
    "    if status_code == 420:\n",
    "      print('Too many requests!')\n",
    "  \n",
    "  def hashtags(self, data):\n",
    "    words = data['text'].split()\n",
    "    hashtags = list(filter(lambda s: s.startswith('#'), words))\n",
    "    hashtags = dict((hashtag, 1) for hashtag in hashtags)\n",
    "    return(hashtags)\n",
    "  \n",
    "  def sum_hashtags(self, x, y):\n",
    "    for key in y:\n",
    "      if key in x:\n",
    "        x[key] += 1\n",
    "      else:\n",
    "        x[key] = 1\n",
    "    return(x)\n",
    "  \n",
    "  def get_counter(self):\n",
    "    return(self.counter)\n",
    "\n",
    "  def get_hashtags(self):\n",
    "    return(self.sink)\n",
    "  \n",
    "  def clean_sink(self):\n",
    "    for key in self.sink:\n",
    "      value = self.sink[key]\n",
    "      if value == 1:\n",
    "        self.sink.pop(key)\n",
    "  \n",
    "  def get_filter_hashtags(self):\n",
    "    out = {}\n",
    "    for key in self.sink:\n",
    "      value = self.sink[key]\n",
    "      if value > 1:\n",
    "        out[key] = value\n",
    "    return(out)\n",
    "  \n",
    "  def get_filter_hashtags_df(self):\n",
    "    htags = self.get_filter_hashtags()\n",
    "    keys = list(htags.keys())\n",
    "    values = list(htags.values())\n",
    "    out = pd.DataFrame({'hashtags': keys, 'count': values})\n",
    "    out = out.sort_values('count', ascending=False)\n",
    "    return(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "stream_listener = StreamListener(time_limit=7200)\n",
    "tracker = ['trump', 'donald trump']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "stream_listener.running = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "stream = tweepy.Stream(auth=api.auth, listener=stream_listener)\n",
    "stream.filter(track=tracker, is_async=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get top 10 hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hashtags</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [hashtags, count]\n",
       "Index: []"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-5:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/max/minimamba/envs/aai/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/max/minimamba/envs/aai/lib/python3.8/threading.py\", line 870, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/max/minimamba/envs/aai/lib/python3.8/site-packages/tweepy/streaming.py\", line 320, in _run\n",
      "    six.reraise(*exc_info)\n",
      "  File \"/home/max/minimamba/envs/aai/lib/python3.8/site-packages/six.py\", line 703, in reraise\n",
      "    raise value\n",
      "  File \"/home/max/minimamba/envs/aai/lib/python3.8/site-packages/tweepy/streaming.py\", line 289, in _run\n",
      "    self._read_loop(resp)\n",
      "  File \"/home/max/minimamba/envs/aai/lib/python3.8/site-packages/tweepy/streaming.py\", line 351, in _read_loop\n",
      "    self._data(next_status_obj)\n",
      "  File \"/home/max/minimamba/envs/aai/lib/python3.8/site-packages/tweepy/streaming.py\", line 323, in _data\n",
      "    if self.listener.on_data(data) is False:\n",
      "  File \"/home/max/minimamba/envs/aai/lib/python3.8/site-packages/tweepy/streaming.py\", line 54, in on_data\n",
      "    if self.on_status(status) is False:\n",
      "  File \"<ipython-input-103-fd9259355cc9>\", line 47, in on_status\n",
      "  File \"<ipython-input-103-fd9259355cc9>\", line 80, in clean_sink\n",
      "RuntimeError: dictionary changed size during iteration\n"
     ]
    }
   ],
   "source": [
    "def count_capitals(word):\n",
    "  count = sum(1 for c in word if c.isupper())\n",
    "  return(count)\n",
    "\n",
    "def merge_hashtags(df):\n",
    "  out = {}\n",
    "  vdf = df.values\n",
    "  for t in vdf:\n",
    "    key = t[0]\n",
    "    val = t[1]\n",
    "    keys_lower = map(str.lower, out.keys())\n",
    "    key_lower = key.lower()\n",
    "    if key_lower in keys_lower:\n",
    "      for ok in out.keys():\n",
    "        if key_lower == ok.lower():\n",
    "          key_old = ok\n",
    "          key_new = key\n",
    "      capitals_old = count_capitals(key_old)\n",
    "      capitals_new = count_capitals(key_new)\n",
    "      if capitals_new > capitals_old:\n",
    "        out[key_new] = out[key_old] + val\n",
    "        out.pop(key_old)\n",
    "      else:\n",
    "        out[key_old] += val\n",
    "    else:\n",
    "      out[key] = val\n",
    "  htags = list(out.keys())\n",
    "  vals = list(out.values())\n",
    "  df = pd.DataFrame({'hashtags': htags, 'count': vals})\n",
    "  df_out = df.sort_values('count', ascending=False).reset_index()[['hashtags', 'count']]\n",
    "  return(df_out)\n",
    "\n",
    "df = stream_listener.get_filter_hashtags_df()\n",
    "df = merge_hashtags(df)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'#trump2020': 1, '#MakeChinaPay': 1, '#Vote2020': 1, '#voteoutdemocrats': 1}\n"
     ]
    }
   ],
   "source": [
    "with open('twitter.json', 'r') as f:\n",
    "  dump = json.load(f)\n",
    "  for data in dump:\n",
    "    if data['id'] == '1282929875997749249':\n",
    "      sample = data\n",
    "def hashtags(data):\n",
    "    words = data['text'].split()\n",
    "    hashtags = list(filter(lambda s: s.startswith('#'), words))\n",
    "    hashtags = dict((hashtag, 1) for hashtag in hashtags)\n",
    "    return(hashtags)\n",
    "test = hashtags(sample)\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'#trump2020': 1, '#MakeChinaPay': 1, '#Vote2020': 1, '#voteoutdemocrats': 1, '#Trump': 2, '#Biden,': 1, '#Corona,': 1}\n"
     ]
    }
   ],
   "source": [
    "x = {'#trump2020': 1, '#MakeChinaPay': 1, '#Vote2020': 1, '#voteoutdemocrats': 1}\n",
    "y = {'#Trump': 1, '#Biden,': 1}\n",
    "z = {'#Trump': 1, '#Corona,': 1}\n",
    "def sum_hashtags(x, y):\n",
    "  for key in y:\n",
    "    if key in x:\n",
    "      x[key] += 1\n",
    "    else:\n",
    "      x[key] = 1\n",
    "  return(x)\n",
    "test = sum_hashtags(x, y)\n",
    "test = sum_hashtags(x, z)\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04e1e626b8cb46969403bbc1febe2f9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from streamz import Stream\n",
    "\n",
    "tsample = '@realDonaldTrump Let China pay for this\\n\\nVote Trump this November \\n\\n#trump2020 #MakeChinaPay #Vote2020 #voteoutdemocrats'\n",
    "\n",
    "source = Stream()\n",
    "source\\\n",
    "  .map(hashtags)\\\n",
    "  .accumulate(sum_hashtags)\\\n",
    "  .sink(print)\n",
    "#source.map(hashtags).sink(print)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'#trump2020': 2, '#MakeChinaPay': 2, '#Vote2020': 2, '#voteoutdemocrats': 2}\n"
     ]
    }
   ],
   "source": [
    "source.emit(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "description = status.user.description\n",
    "loc = status.user.location\n",
    "text = status.text\n",
    "coords = status.coordinates\n",
    "name = status.user.screen_name\n",
    "user_created = status.user.created_at\n",
    "followers = status.user.followers_count\n",
    "id_str = status.id_str\n",
    "created = status.created_at\n",
    "retweets = status.retweet_count\n",
    "bg_color = status.user.profile_background_color\n",
    "```\n",
    "\n",
    "interesting objects attributes\n",
    "```\n",
    "text: short text with link\n",
    "user: object(id, name, screen_name, location)\n",
    "extended_tweet(full_text, user_mentions)\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aai",
   "language": "python",
   "name": "aai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
